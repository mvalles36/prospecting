{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "if os.environ['PROJECTDIR'] not in sys.path:\n",
    "    sys.path.insert(1, os.environ['PROJECTDIR'])\n",
    "import prospecting as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler # normal distribution\n",
    "from sklearn.preprocessing import MinMaxScaler # scales data to [0, 1]\n",
    "from sklearn.preprocessing import MaxAbsScaler # scales data to [-1, 1]; for data already centered at zero, or sparse data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize model session, pass reference to pickled dataset\n",
    "dataset_path = os.path.join(p.DATADIR, 'innocentive_dummified_96406_308.p')\n",
    "m = p.ModelSession(dataset_path, testsize=0.2, pcasets=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prospecting.api: INFO     Reading discovery file for sheets:v4\n",
      "prospecting.api: INFO     Authenticating...sheets, v4\n",
      "prospecting.api: INFO     Getting credentials...\n",
      "prospecting.api: INFO     Building service object...\n",
      "prospecting.api: INFO     Service object built...<googleapiclient.discovery.Resource object at 0x000002C2C02F4438>\n",
      "prospecting.api: INFO     Successfully authenticated...sheets, v4\n",
      "prospecting.api: INFO     Spreadsheet loaded.\n",
      "prospecting.api: INFO     Sheets include: ['session_report', 'cv_results', 'BACKUP cv_results v3', 'BACKUP cv_results_v2', 'BACKUP cv_results', 'model_types', '_plots', 'BACKUP_aggregate', '_aggregate_pipeline-pivot', '_Pivot Table 2', '_cell_count']\n"
     ]
    }
   ],
   "source": [
    "# Initialize SheetsApi instance as attribute of ModelSession instance\n",
    "m.ss = p.SheetsApi(spreadsheetid = '1dG5lQfqthqshz45Rs94VLSSWmSrS60b1iw7cT4Rqevs',\n",
    "                   scopelist = ['https://www.googleapis.com/auth/spreadsheets',\n",
    "                                'https://www.googleapis.com/auth/drive.metadata'])\n",
    "m.ss.authenticate()\n",
    "m.ss.info = m.ss.get_ss_info()\n",
    "m.ss.sheets = m.ss.load_sheets(['session_report', 'cv_results', 'model_types'])\n",
    "\n",
    "#Lookup names of model_types to use when reporting on model performance\n",
    "m.lookup_model_types = dict(m.ss.sheets['model_types'].to_dict(orient='split')['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model_config (list):  List of config dictionaries to pass to grid_search; config dictionaries are comprised of:\n",
    "#     pipesteps (list):  List of tuples representing pipeline\n",
    "#     params (dict):  Dictionary of pipeline params to use in GridSearchCV\n",
    "#     scoring (str):  Scoring type to use in GridSearchCV\n",
    "#     datasets (list):  List of strings identifying datasets to use, datasets must be attributes of ModelSession\n",
    "#     n_jobs (int):  Number of cores to use during GridSearchCV, default=3 (optional)\n",
    "\n",
    "model_config = [{'pipesteps': [('stdsc', StandardScaler()), ('lr', LogisticRegression())],\n",
    "                 'params': {'lr__C':[0.25],\n",
    "                            'lr__penalty':['l1', 'l2'],\n",
    "                            'lr__class_weight':[None, 'balanced']},\n",
    "                 'scoring': 'roc_auc',\n",
    "                 'datasets': ['X_train']},\n",
    "                {'pipesteps': [('mmsc', MinMaxScaler()), ('lr', LogisticRegression())],\n",
    "                 'params': {'lr__C':[0.5],\n",
    "                            'lr__penalty':['l1', 'l2'],\n",
    "                            'lr__class_weight':[None, 'balanced']},\n",
    "                 'scoring': 'roc_auc',\n",
    "                 'datasets': ['X_train']},\n",
    "                {'pipesteps': [('masc', MaxAbsScaler()), ('lr', LogisticRegression())],\n",
    "                 'params': {'lr__C':[0.01, 0.1, 0.5, 1],\n",
    "                            'lr__penalty':['l1', 'l2'],\n",
    "                            'lr__class_weight':[None, 'balanced']},\n",
    "                 'scoring': 'roc_auc',\n",
    "                 'datasets': ['X_train']},\n",
    "                {'pipesteps': [('rfc', RandomForestClassifier())],\n",
    "                 'params': {'rfc__n_estimators':[250, 300],\n",
    "                            'rfc__max_depth':[19, 25]},\n",
    "                 'scoring': 'roc_auc',\n",
    "                 'datasets': ['X_train']}\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  12 out of  12 | elapsed:  9.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prospecting.report: INFO     Appending df_cv_results to cv_results tab in spreadsheet.\n",
      "prospecting.api: INFO     Append Successful!\n",
      "prospecting.model: INFO     Confusion matrix:\n",
      "[[6679 2917]\n",
      " [2571 7115]]\n",
      "prospecting.api: INFO     Append Successful!\n",
      "prospecting.report: INFO     Report complete in 0.3550238609313965 seconds\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  12 out of  12 | elapsed: 10.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prospecting.report: INFO     Appending df_cv_results to cv_results tab in spreadsheet.\n",
      "prospecting.api: INFO     Append Successful!\n",
      "prospecting.model: INFO     Confusion matrix:\n",
      "[[6687 2909]\n",
      " [2576 7110]]\n",
      "prospecting.api: INFO     Append Successful!\n",
      "prospecting.report: INFO     Report complete in 0.34902143478393555 seconds\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  48 out of  48 | elapsed:  7.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prospecting.report: INFO     Appending df_cv_results to cv_results tab in spreadsheet.\n",
      "prospecting.api: INFO     Append Successful!\n",
      "prospecting.model: INFO     Confusion matrix:\n",
      "[[6683 2913]\n",
      " [2567 7119]]\n",
      "prospecting.api: INFO     Append Successful!\n",
      "prospecting.report: INFO     Report complete in 0.3020155429840088 seconds\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  12 out of  12 | elapsed: 11.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prospecting.report: INFO     Appending df_cv_results to cv_results tab in spreadsheet.\n",
      "prospecting.api: INFO     Append Successful!\n",
      "prospecting.model: INFO     Confusion matrix:\n",
      "[[6368 3228]\n",
      " [2096 7590]]\n",
      "prospecting.api: INFO     Append Successful!\n",
      "prospecting.report: INFO     Report complete in 0.3010680675506592 seconds\n"
     ]
    }
   ],
   "source": [
    "p.model.grid_search(m, model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## APPENDIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To create PCA plots, exclude pcasets=False from m = p.ModelSession(dataset_path, testsize=0.2)\n",
    "plots_dir = 'C:\\\\Users\\\\Reid\\\\Google Drive\\\\projects\\\\innocentive\\\\plots'\n",
    "p.report.plot_pca_expvar_to_pdf(m, plots_dir)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
